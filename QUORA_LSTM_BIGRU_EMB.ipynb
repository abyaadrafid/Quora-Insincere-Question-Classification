{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import logging\nimport pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport re\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.metrics import f1_score\nfrom torch import optim\nimport torchtext\nimport random\nfrom gensim.models import KeyedVectors\nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import f1_score, roc_auc_score\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train= pd.read_csv('../input/quora-insincere-questions-classification/train.csv')\ndf_test= pd.read_csv('../input/quora-insincere-questions-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_coefs(word,*arr): \n    return word, np.asarray(arr, dtype='float32')[:300]\ndef load_embedding(file):\n    if file == '../input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n    else:\n        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n    return embeddings_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newspath = '../input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n#googlenews = KeyedVectors.load_word2vec_format(newspath, binary=True)\nfrom gensim import utils\nmax_features = 95000\n\ndef load_word2vec(fname, encoding='utf8', unicode_errors='strict',datatype=np.float32, word_index=None):\n    emb_mean,emb_std = -0.0051106834, 0.18445626\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, 300))\n    with utils.smart_open(fname) as fin:\n        header = utils.to_unicode(fin.readline(), encoding=encoding)\n        vocab_size, vector_size = (int(x) for x in header.split())\n        binary_len = np.dtype(datatype).itemsize * vector_size\n        for _ in tqdm(range(vocab_size)):\n            # mixed text and binary: read text first, then binary\n            word = []\n            while True:\n                ch = fin.read(1)\n                if ch == b' ':\n                    break\n                if ch == b'':\n                    raise EOFError(\"unexpected end of input\")\n                if ch != b'\\n':\n                    word.append(ch)\n            word = utils.to_unicode(b''.join(word), encoding=encoding, errors=unicode_errors)\n            weights = np.fromstring(fin.read(binary_len), dtype=datatype).astype(datatype)\n            if word not in word_index:\n                continue\n            i = word_index[word]\n            if i >= max_features:\n                continue\n            embedding_matrix[i] = weights\n    return embedding_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove = load_embedding('../input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paragram = load_embedding('../input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(x):\n    x = str(x)\n    for punct in puncts:\n        x = x.replace(punct, ' %s '%punct)\n    return x\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"that's\" : \"that is\",\n\"there's\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_word_mispell_dict = {\n                'whta': 'what', 'howdo': 'how do', 'Whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', \n                'howmany': 'how many', 'whydo': 'why do', 'doi': 'do i', 'howdoes': 'how does', \"whst\": 'what', \n                'shoupd': 'should', 'whats': 'what is', \"im\": \"i am\", \"whatis\": \"what is\", \"iam\": \"i am\", \"wat\": \"what\",\n                \"wht\": \"what\",\"whts\": \"what is\", \"whtwh\": \"what\", \"whtat\": \"what\", \"whtlat\": \"what\", \"dueto to\": \"due to\",\n                \"dose\": \"does\", \"wha\": \"what\", 'hw': \"how\", \"its\": \"it is\", \"whay\": \"what\", \"ho\": \"how\", \"whart\": \"what\", \n                \"woe\": \"wow\", \"wt\": \"what\", \"ive\": \"i have\",\"wha\": \"what\", \"wich\": \"which\", \"whic\": \"which\", \"whys\": \"why\", \n                \"doe\": \"does\", \"wjy\": \"why\", \"wgat\": \"what\", \"hiw\": \"how\",\"howto\": \"how to\", \"lets\": \"let us\", \"haw\": \"how\", \n                \"witch\": \"which\", \"wy\": \"why\", \"girlfriend\": \"girl friend\", \"hows\": \"how is\",\"whyis\": \"why is\", \"whois\": \"who is\",\n                \"dont\": \"do not\", \"hat\": \"what\", \"whos\": \"who is\", \"whydoes\": \"why does\", \"whic\": \"which\",\"hy\": \"why\", \"w? hy\": \"why\",\n                \"ehat\": \"what\", \"whate\": \"what\", \"whai\": \"what\", \"whichis\": \"which is\", \"whi\": \"which\", \"isit\": \"is it\",\"ca\": \"can\", \n                \"wwhat\": \"what\", \"wil\": \"will\", \"wath\": \"what\", \"plz\": \"please\", \"ww\": \"how\", \"hou\": \"how\", \"whch\": \"which\",\n                \"ihave\": \"i have\", \"cn\": \"can\", \"doesnt\": \"does not\", \"shoul\": \"should\", \"whatdo\": \"what do\", \"isnt\": \"is not\", \n                \"whare\": \"what are\",\"whick\": \"which\", \"whatdoes\": \"what does\", \"hwo\": \"how\", \"howdid\": \"how did\", \"why dose\": \"why does\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\nmispellings, mispellings_re = _get_mispell(mispell_dict)\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n    return mispellings_re.sub(replace, text)\n\ndef correct_first_word(x):\n    for key in first_word_mispell_dict.keys():\n        if x.startswith(key + \" \"):\n            x = x.replace(key + \" \", first_word_mispell_dict[key] + \" \")\n            break\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"vocab\"] = df_train[\"question_text\"].progress_apply(lambda x : correct_first_word(x))\ndf_test[\"vocab\"] = df_test[\"question_text\"].progress_apply(lambda x : correct_first_word(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"vocab\"] = df_train[\"vocab\"].progress_apply(lambda x : clean_text(x))\ndf_test[\"vocab\"] = df_test[\"vocab\"].progress_apply(lambda x : clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"vocab\"] = df_train[\"vocab\"].progress_apply(lambda x : clean_numbers(x))\ndf_test[\"vocab\"] = df_test[\"vocab\"].progress_apply(lambda x : clean_numbers(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"vocab\"] = df_train[\"vocab\"].progress_apply(lambda x : replace_typical_misspell(x))\ndf_test[\"vocab\"] = df_test[\"vocab\"].progress_apply(lambda x : replace_typical_misspell(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = df_train[\"vocab\"]\ntestX = df_test[\"vocab\"]\ndata = pd.concat((trainX,testX),axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(oov_token = 'xxunk',filters='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(list(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = tokenizer.texts_to_sequences(trainX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX = tokenizer.texts_to_sequences(testX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = pad_sequences(trainX, maxlen=800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX = pad_sequences(testX, maxlen=800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainy = df_train[\"target\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_embedding_matrix(embedding_index, word_index, embedding_mean, embedding_std,a=0):\n    all_embs = np.stack(embedding_index.values())\n    embedding_size = all_embs.shape[1]\n    word_number = len(word_index)\n    embedding_matrix = np.random.normal(embedding_mean, embedding_std , (word_number,embedding_size))\n    \n    for word, i in word_index.items():\n        embedding_vector = embedding_index.get(word)\n\n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector\n        else:\n            embedding_vector = embedding_index.get(word.capitalize())\n            if embedding_vector is not None: \n                embedding_matrix[i] = embedding_vector\n    return embedding_matrix ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_mat = make_embedding_matrix(glove, tokenizer.word_index, -0.05838499, 0.48782197)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paragram_mat = make_embedding_matrix(paragram, tokenizer.word_index, -0.0053247833, 0.49346462)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = np.concatenate((glove_mat,paragram_mat),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_embeddings= 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = torch.tensor(testX,dtype=torch.long)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = torch.utils.data.TensorDataset(x_test)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, valid_x, train_y, valid_y = train_test_split(trainX,trainy, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_preds = np.zeros(len(valid_y))\ntest_preds = np.zeros(len(testX))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = torch.tensor(train_x,dtype=torch.long)\nx_valid = torch.tensor(valid_x,dtype=torch.long)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = torch.tensor(train_y.reshape(len(train_y), 1), dtype=torch.float32)\ny_valid = torch.tensor(valid_y.reshape(len(valid_y), 1), dtype=torch.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = torch.utils.data.TensorDataset(x_train, y_train)\nvalid_ds = torch.utils.data.TensorDataset(x_valid, y_valid)\n\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EMBEDDING_DROPOUT(nn.Module):\n    def __init__(self, embedding_matrix, max_features = 215224, embedding_size = 300):\n        super(EMBEDDING_DROPOUT,self).__init__()\n        self.embedding = nn.Embedding(max_features, embedding_size*num_embeddings)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = False\n        \n        self.embedding_drop = nn.Dropout2d(0.1)\n    \n    def forward(self,x):\n        h_embedding = self.embedding(x)\n        h_embedding = torch.squeeze(self.embedding_drop(torch.unsqueeze(h_embedding, 0)))\n        return h_embedding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LSTM_GRU(nn.Module):\n    def __init__ (self, embedding_size= 300, hidden_size= 128):\n        super(LSTM_GRU,self).__init__()\n        self.lstm = nn.LSTM(embedding_size*num_embeddings, hidden_size, bidirectional=True, batch_first=True)\n        self.gru = nn.GRU(hidden_size*2, hidden_size, bidirectional=True, batch_first=True)\n    \n    def forward(self,x):\n        h_lstm, _ = self.lstm(x)\n        h_gru, _ = self.gru(h_lstm)\n        \n        return h_gru, h_lstm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LINEAR_LAYER(nn.Module):\n    def __init__(self,embedding_size= 300,intermediate_layer=64,maxlen=800,hidden_size=128):\n        super(LINEAR_LAYER,self).__init__()\n        self.linear = nn.Linear(hidden_size,intermediate_layer)\n        self.dropout = nn.Dropout(0.15)\n        self.bn = nn.BatchNorm1d(intermediate_layer)\n        self.output = nn.Linear(intermediate_layer, 1)\n        \n    def forward(self,x):\n        return self.output(self.bn(self.dropout(self.linear(x))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self, embedding_matrix,max_features=215224,embedding_size=300,maxlen=800, hidden_size=128):\n        super(NeuralNet,self).__init__()\n        self.embedding = EMBEDDING_DROPOUT(embedding_matrix,max_features,embedding_size)\n        self.stem = LSTM_GRU(embedding_size,hidden_size)\n        self.regressor = LINEAR_LAYER(embedding_size=embedding_size,maxlen=maxlen,hidden_size =hidden_size*4*2 )\n    \n    def forward(self,x):\n        embedding_output = self.embedding(x)\n        h_lstm, h_gru = self.stem(embedding_output)\n        \n        l_maxpool, _ = torch.max(h_lstm,1)\n        l_avgpool = torch.mean(h_lstm,1)\n        g_maxpool, _ = torch.max(h_gru,1)\n        g_avgpool = torch.mean(h_gru,1)\n        \n        features = torch.cat((l_maxpool,l_avgpool,g_maxpool,g_avgpool),1)\n        return self.regressor(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = NeuralNet(embedding_matrix).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\noptimizer = torch.optim.Adam(model.parameters())\nstep_size = 300\n\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer,0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(10):\n    print('Epoch: %d'%epoch+1)\n    iteration=0\n    running_loss=0.0\n    model.train()\n    for inputs,targets in tqdm(train_dl):\n        inputs= inputs.cuda()\n        targets= targets.cuda()\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        \n        optimizer.step()\n        \n        loss = loss.item()\n        running_loss+= loss\n        iteration+=1\n\n    tr_loss = running_loss / iteration\n    print('Train: Loss: %.6f'%tr_loss)\n    \n    iteration = 0\n    running_loss = 0.0\n    running_acc = 0.0\n    model.eval()\n    \n    with torch.no_grad():\n        for inputs, targets in tqdm(valid_dl):\n            inputs=inputs.cuda()\n            targets=targets.cuda() \n            outputs = model(inputs)\n            loss = loss_fn(outputs, targets)\n            loss = loss.item()\n            running_loss += loss\n            iteration+=1\n        \n        va_loss = running_loss / iteration\n        print('Valid: Loss: %.6f'%va_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs = np.zeros([1,1])\nfor inputs,_ in tqdm(train_dl):\n    output = model(inputs.cuda(2))\n    outputs = np.concatenate((outputs,output.detach()),axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bestThresshold(y_train,train_preds):\n    tmp = [0,0,0] # idx, cur, max\n    delta = 0\n    for tmp[0] in tqdm(np.arange(0.1, 0.501, 0.01)):\n        tmp[1] = f1_score(y_train, np.array(train_preds)>tmp[0])\n        if tmp[1] > tmp[2]:\n            delta = tmp[0]\n            tmp[2] = tmp[1]\n    print('best threshold is {:.4f} with F1 score: {:.4f}'.format(delta, tmp[2]))\n    return delta , tmp[2]\n\ndelta, _ = bestThresshold(y_train,outputs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}